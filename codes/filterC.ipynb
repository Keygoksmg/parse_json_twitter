{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import path\n",
    "from glob import glob\n",
    "\n",
    "import ijson\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-81e058b0cba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdfrts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcsvfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsvfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdfrts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[1;32m    544\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Mar data\n",
    "zip_dir  = \"../data/new_dfs_jst\"\n",
    "csvfiles = glob(os.path.join(zip_dir, 'dfor*'))\n",
    "\n",
    "dfrts = []\n",
    "for csvfile in csvfiles:\n",
    "    df1 = pd.read_csv(csvfile).drop('Unnamed: 0', axis=1)\n",
    "    dfrts.append(df1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb data\n",
    "zip_dir  = \"../data/new_dfs2_jst\"\n",
    "csvfiles = glob(os.path.join(zip_dir, 'dfor*'))\n",
    "\n",
    "dfors = []\n",
    "for csvfile in csvfiles:\n",
    "    df = pd.read_csv(csvfile).drop('Unnamed: 0', axis=1)\n",
    "    dfors.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-03-10', '2020-03-09', '2020-03-08', '2020-03-07'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfors[7]\n",
    "df.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>RT_flag</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2775144644</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>不満気な様でだるく 息を吸い込む仕方ないふりで 睨み吐き出すそれが無駄と気づき 髪を切った朝...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>04:47:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013069463120277504</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>伝えたいけど完全迷惑になるって分かってるから伝えれない不快な思いをさせたくない困った表情にさ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>04:47:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2561329940</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>@Dragoooon1223 50分ずっと観察してても飽きない！(๑•̀ㅂ•́)و✧ナルガち...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>04:47:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>729977246</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>■ストレスの大半は自分もしくは他の人から課された「やるべきこと」がうまく片付かないことから生...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>04:47:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104191938083741696</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>どら焼きに挟まれたバンテ君と、どら焼きをイデアに取られて怒った バンテ君笑笑 https:/...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>04:47:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id        date  \\\n",
       "0           2775144644  2020-03-07   \n",
       "1  1013069463120277504  2020-03-07   \n",
       "2           2561329940  2020-03-07   \n",
       "3            729977246  2020-03-07   \n",
       "4  1104191938083741696  2020-03-07   \n",
       "\n",
       "                                               tweet  RT_flag  year  month  \\\n",
       "0  不満気な様でだるく 息を吸い込む仕方ないふりで 睨み吐き出すそれが無駄と気づき 髪を切った朝...    False  2020      3   \n",
       "1  伝えたいけど完全迷惑になるって分かってるから伝えれない不快な思いをさせたくない困った表情にさ...    False  2020      3   \n",
       "2  @Dragoooon1223 50分ずっと観察してても飽きない！(๑•̀ㅂ•́)و✧ナルガち...    False  2020      3   \n",
       "3  ■ストレスの大半は自分もしくは他の人から課された「やるべきこと」がうまく片付かないことから生...    False  2020      3   \n",
       "4  どら焼きに挟まれたバンテ君と、どら焼きをイデアに取られて怒った バンテ君笑笑 https:/...    False  2020      3   \n",
       "\n",
       "   day  hour      time  \n",
       "0    7     4  04:47:58  \n",
       "1    7     4  04:47:58  \n",
       "2    7     4  04:47:57  \n",
       "3    7     4  04:47:56  \n",
       "4    7     4  04:47:55  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df308 = df[df.date == '2020-03-08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df308)\n",
    "d = df308[df308['tweet'].str.contains('放心状態')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7234"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "25\n",
      "23\n",
      "22\n",
      "20\n",
      "16\n",
      "17\n",
      "26\n",
      "22\n",
      "19\n",
      "30\n",
      "22\n",
      "30\n",
      "38\n",
      "32\n",
      "21\n",
      "33\n",
      "53\n",
      "54\n",
      "6632\n",
      "63\n",
      "63\n",
      "76\n",
      "97\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "times = ['01:', '02:', '03:', '04:', '05:', '06:', '07:', '08:', '09:', '10:',\n",
    "         '11:', '12:', '13:', '14:', '15:', '16:', '17:', '18:', '19:', '20:',\n",
    "         '21:', '21:','22:', '23:','24:']\n",
    "for key in times:\n",
    "    print(len(d[d['time'].str.contains(key)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>RT_flag</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409646</th>\n",
       "      <td>421890848</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>@MAMAMIRAFAN ありがとうございますありがとうございます＼(^o^)／もうあのどア...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20:59:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409977</th>\n",
       "      <td>1220906671683207168</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>ヨンジュンとカイくんのDOPE見ちゃってもう放心状態なんだけど何あれ殺しに来てる無理しんどい🥵</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20:58:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410358</th>\n",
       "      <td>1215840378</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>@shoback5 当時見てました！😃元はOVA作品でしたよね☝🏼エヴァが完結して放心状態の...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20:57:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410540</th>\n",
       "      <td>1175418033046605824</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>@hanana8blueyoa わたしも半ば放心状態…</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410642</th>\n",
       "      <td>1208280841484292097</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>@keisetu_seiken …←目が放心状態 https://t.co/ULo3ckKk66</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>20:57:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id        date  \\\n",
       "409646            421890848  2020-03-08   \n",
       "409977  1220906671683207168  2020-03-08   \n",
       "410358           1215840378  2020-03-08   \n",
       "410540  1175418033046605824  2020-03-08   \n",
       "410642  1208280841484292097  2020-03-08   \n",
       "\n",
       "                                                    tweet  RT_flag  year  \\\n",
       "409646  @MAMAMIRAFAN ありがとうございますありがとうございます＼(^o^)／もうあのどア...    False  2020   \n",
       "409977    ヨンジュンとカイくんのDOPE見ちゃってもう放心状態なんだけど何あれ殺しに来てる無理しんどい🥵    False  2020   \n",
       "410358  @shoback5 当時見てました！😃元はOVA作品でしたよね☝🏼エヴァが完結して放心状態の...    False  2020   \n",
       "410540                        @hanana8blueyoa わたしも半ば放心状態…    False  2020   \n",
       "410642   @keisetu_seiken …←目が放心状態 https://t.co/ULo3ckKk66    False  2020   \n",
       "\n",
       "        month  day  hour      time  \n",
       "409646      3    8    20  20:59:49  \n",
       "409977      3    8    20  20:58:55  \n",
       "410358      3    8    20  20:57:47  \n",
       "410540      3    8    20  20:57:19  \n",
       "410642      3    8    20  20:57:02  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = d[d['hour'] == 20]\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@airi19254081 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに🙈… https://t.co/EufqL74syz    1\n",
       "@ldh_rkyw 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに🙈今す… https://t.co/p3hWEBFcUi      1\n",
       "@s99_520 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに🙈今すぐ… https://t.co/SRu0l81X96      1\n",
       "@gurujann 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに🙈今す… https://t.co/8f3y8jD5xP      1\n",
       "@oVS8oqyGv17r4fu 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメ… https://t.co/bDGvWpD7Qd    1\n",
       "                                                                                                                                      ..\n",
       "@yutakamaiyan 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに🙈… https://t.co/RzfVzga34A    1\n",
       "@morehappylife 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに… https://t.co/FOLKCsdqDI    1\n",
       "@Misaki_Yuta2217 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメ… https://t.co/V3a916LZKh    1\n",
       "@8Y5oLjw0Js7goSl 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメ… https://t.co/xeLdFZrTxV    1\n",
       "@rkrk2057_saki 🆕#GENE高 このあとすぐ🆕#GENE がドバイを満喫中😍!!王様の家でゴーカート体験🏎過激なドリフトで放心状態に🤣!?さらに激カワ❤️ホワイトライオンの赤ちゃん抱っこでメロメロに… https://t.co/vh9BOy9hvz    1\n",
       "Name: tweet, Length: 6620, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['tweet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6573"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm = target[target['tweet'].str.contains('GENE高')]\n",
    "len(spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6573"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)-len(spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter V4 by 'エロい' - Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filetypes = ['T', 'D', 'A', 'V', 'F', 'C']\n",
    "def filterV4(dfors, filetype, savedir, key_lang, filt_flag):\n",
    "    # Prepartion of dfw \n",
    "    results = []\n",
    "    dfs = []\n",
    "    dfw = pd.read_csv('../data/WordTimeSeries.csv', encoding='utf-8').rename(columns={'Unnamed: 0': 'types',\n",
    "                                                                                    'file name': 'file_name', \n",
    "                                                                                    'orignal form': 'orignal_form',\n",
    "                                                                                    'English translation': 'English_translation'})\n",
    "    booleanDictionary = {True: 'TRUE', False: 'FALSE'} # Drop nan and False in order to use query \n",
    "    dfw = dfw.replace(booleanDictionary)\n",
    "    dfw = dfw.dropna(how='all')\n",
    "    \n",
    "    # Prepration of keywords\n",
    "    filenames = [filename for filename in dfw.file_name.tolist() if filetype in filename]\n",
    "    xd = {}\n",
    "    xd['T'] = 'file_name.str.contains(\"T\")'\n",
    "    xd['D'] = 'file_name.str.contains(\"D\")'\n",
    "    xd['A'] = 'file_name.str.contains(\"A\")'\n",
    "    xd['V'] = 'file_name.str.contains(\"V\")'\n",
    "    xd['F'] = 'file_name.str.contains(\"F\")'\n",
    "    xd['C'] = 'file_name.str.contains(\"C\")'\n",
    "    \n",
    "    query = xd[filetype]\n",
    "    dfw_c = dfw.query(query, engine='python')\n",
    "    if key_lang == 'jp':\n",
    "        keywords = dfw_c.orignal_form.tolist() # English.ver: keywords = dfw_c.English_translation.tolist() \n",
    "    elif key_lang == 'en':\n",
    "        keywords = dfw_c.English_translation.tolist() \n",
    "    else:\n",
    "        print('Put accurate keyword language')\n",
    "            \n",
    "    # Find tweets\n",
    "    for i, dfor in tqdm(enumerate(dfors)):\n",
    "         # Extract tweet\n",
    "        dfor_c = dfor[dfor['tweet'].str.contains('|'.join(keywords))]\n",
    "        \n",
    "        # Add columns of keywords whose cell have 1 if this tweet includes a keyword \n",
    "        for col, key in zip(filenames, keywords):\n",
    "            l = []\n",
    "            for row in dfor_c.itertuples():\n",
    "                if key in row.tweet:\n",
    "                    l.append(1)\n",
    "                else:\n",
    "                    l.append(0)\n",
    "            dfor_c[col] = l\n",
    "        \n",
    "        d4 = dfor_c[dfor_c.C4 == 1]\n",
    "        \n",
    "        # Finally Connect dfs\n",
    "        if i == 0:\n",
    "            dfnew = d4\n",
    "        else:\n",
    "            dfnew = pd.concat([dfnew, d4], axis=0)\n",
    "    \n",
    "    \n",
    "    # DF Only V4\n",
    "    d4 = dfnew[dfnew.C12 == 1].drop(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', \n",
    "                                    'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', \n",
    "                                    'C31', 'C32', 'C33', 'C34', 'C35'], axis = 1)\n",
    "    if filt_flag:\n",
    "        # Remove 'エロい'\n",
    "        d4_without_eroi = d4[~d4['tweet'].str.contains('エロい', na = False)]\n",
    "        outname = 'V4b.csv'\n",
    "    else:\n",
    "        d4_without_eroi = d4\n",
    "        outname = 'V4a.csv'\n",
    "\n",
    "#      # Make rows\n",
    "#     uni_dates = d4_without_eroi['date'].tolist()\n",
    "#     uni_dates = sorted(set(uni_dates), key=uni_dates.index) # date values\n",
    "#     rows = []\n",
    "#     for date in uni_dates:\n",
    "#         r = d4_without_eroi.groupby('date').get_group(date).V4.sum()\n",
    "#         rows.append(r)\n",
    "#     data = np.array([uni_dates, rows]).T\n",
    "#     # columns\n",
    "#     cols = ['date', 'V4']\n",
    "#     # Create DataFrame\n",
    "#     dft = pd.DataFrame(data, columns=cols).groupby('date').sum()\n",
    "    \n",
    "#     # Save to csv\n",
    "#     outdir = savedir\n",
    "#     if not os.path.exists(outdir):\n",
    "#             os.makedirs(outdir)\n",
    "#     savename = os.path.join(outdir, outname)\n",
    "#     dft.to_csv(savename)\n",
    "            \n",
    "#     return dft\n",
    "\n",
    "    return d4_without_eroi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "10it [01:35,  9.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "filetypes = ['C']\n",
    "for filetype in filetypes:\n",
    "    d4_without_eroi = filterV4(dfors, filetype=filetype, savedir='../new_results_jst2/orjp/day', key_lang='jp', filt_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "10it [00:31,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# RT\n",
    "filetypes = ['V']\n",
    "for filetype in filetypes:\n",
    "    d4_without_eroi = filterV4(dfrts, filetype=filetype, savedir='../new_results2/rtjp/day', key_lang='jp', filt_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-31</th>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>2898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04</th>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05</th>\n",
       "      <td>2403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-06</th>\n",
       "      <td>2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-07</th>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-08</th>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-09</th>\n",
       "      <td>2688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-11</th>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>2307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>2393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14</th>\n",
       "      <td>2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-15</th>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16</th>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17</th>\n",
       "      <td>2412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>4712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-19</th>\n",
       "      <td>2487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-20</th>\n",
       "      <td>2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-21</th>\n",
       "      <td>2447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-22</th>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24</th>\n",
       "      <td>2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25</th>\n",
       "      <td>2716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-26</th>\n",
       "      <td>3291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27</th>\n",
       "      <td>3323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28</th>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V4\n",
       "date            \n",
       "2020-01-31   568\n",
       "2020-02-01  2336\n",
       "2020-02-02  2898\n",
       "2020-02-03  2461\n",
       "2020-02-04  2492\n",
       "2020-02-05  2403\n",
       "2020-02-06  2268\n",
       "2020-02-07  2005\n",
       "2020-02-08  2171\n",
       "2020-02-09  2688\n",
       "2020-02-10  2278\n",
       "2020-02-11  2664\n",
       "2020-02-12  2307\n",
       "2020-02-13  2393\n",
       "2020-02-14  2275\n",
       "2020-02-15  2232\n",
       "2020-02-16  2919\n",
       "2020-02-17  2412\n",
       "2020-02-18  4712\n",
       "2020-02-19  2487\n",
       "2020-02-20  2409\n",
       "2020-02-21  2447\n",
       "2020-02-22  2337\n",
       "2020-02-23  2517\n",
       "2020-02-24  2786\n",
       "2020-02-25  2716\n",
       "2020-02-26  3291\n",
       "2020-02-27  3323\n",
       "2020-02-28  2891\n",
       "2020-02-29  2062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4_without_eroi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter V4 by 'エロい' - hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filetypes = ['T', 'D', 'A', 'V', 'F', 'C']\n",
    "def findtwt_hour(dfors, filetype, savedir, key_lang, filt_flag):\n",
    "    # Prepartion of dfw \n",
    "    results = []\n",
    "    dfs = []\n",
    "    dfw = pd.read_csv('../data/WordTimeSeries.csv', encoding='utf-8').rename(columns={'Unnamed: 0': 'types',\n",
    "                                                                                    'file name': 'file_name', \n",
    "                                                                                    'orignal form': 'orignal_form',\n",
    "                                                                                    'English translation': 'English_translation'})\n",
    "    booleanDictionary = {True: 'TRUE', False: 'FALSE'} # Drop nan and False in order to use query \n",
    "    dfw = dfw.replace(booleanDictionary)\n",
    "    dfw = dfw.dropna(how='all')\n",
    "\n",
    "    # Prepration of keywords\n",
    "    filenames = [filename for filename in dfw.file_name.tolist() if filetype in filename]\n",
    "    xd = {}\n",
    "    xd['T'] = 'file_name.str.contains(\"T\")'\n",
    "    xd['D'] = 'file_name.str.contains(\"D\")'\n",
    "    xd['A'] = 'file_name.str.contains(\"A\")'\n",
    "    xd['V'] = 'file_name.str.contains(\"V\")'\n",
    "    xd['F'] = 'file_name.str.contains(\"F\")'\n",
    "    xd['C'] = 'file_name.str.contains(\"C\")'\n",
    "\n",
    "    query = xd[filetype]\n",
    "    dfw_c = dfw.query(query, engine='python')\n",
    "    \n",
    "    # Keyword \n",
    "    if key_lang == 'jp':\n",
    "        keywords = dfw_c.orignal_form.tolist() # English.ver: keywords = dfw_c.English_translation.tolist() \n",
    "    elif key_lang == 'en':\n",
    "        keywords = dfw_c.English_translation.tolist() \n",
    "    else:\n",
    "        print('Put accurate keyword language')\n",
    "    \n",
    "    # Find tweets\n",
    "    for i, dfor in tqdm(enumerate(dfors)):\n",
    "        # Extract tweet\n",
    "        dfor_c = dfor[dfor['tweet'].str.contains('|'.join(keywords))]\n",
    "\n",
    "        for col, key in zip(filenames, keywords):\n",
    "            l = []\n",
    "            for row in dfor_c.itertuples():\n",
    "                if key in row.tweet:\n",
    "                    l.append(1)\n",
    "                else:\n",
    "                    l.append(0)\n",
    "            dfor_c[col] = l\n",
    "#         dfs.append(dfor_c)\n",
    "        \n",
    "        d4 = dfor_c[dfor_c.C12 == 1]\n",
    "        \n",
    "        # Finally Connect dfs\n",
    "        if i == 0:\n",
    "            dfnew = d4\n",
    "        else:\n",
    "            dfnew = pd.concat([dfnew, d4], axis=0)\n",
    "            \n",
    "\n",
    "    # DF Only c12\n",
    "    d4 = dfnew[dfnew.C12 == 1].drop(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', \n",
    "                                    'C21', 'C22', 'C23', 'C24', 'C25', 'C26', 'C27', 'C28', 'C29', 'C30', \n",
    "                                    'C31', 'C32', 'C33', 'C34', 'C35'], axis = 1)\n",
    "    \n",
    "    if filt_flag:\n",
    "        # Remove 'エロい'\n",
    "        d4_without_eroi = d4[~d4['tweet'].str.contains('GENE高', na = False)]\n",
    "        outname = 'C12b_hour.csv'\n",
    "    else:\n",
    "        d4_without_eroi = d4\n",
    "        outname = 'C12a_hour.csv'\n",
    "        \n",
    "    # Create csv file by day\n",
    "    all_df = []\n",
    "    nextdf, nextdf_date = '', ''\n",
    "    \n",
    "    # Save dir\n",
    "    outdir = savedir\n",
    "    if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "\n",
    "#     for i, df in enumerate(dfs):\n",
    "    df = d4_without_eroi\n",
    "    unique_dates = df['date'].tolist()\n",
    "    unique_dates = sorted(set(unique_dates), key=unique_dates.index) # date values\n",
    "    df_date = df.groupby('date') # df grouped by date   \n",
    "\n",
    "    for date in unique_dates:\n",
    "        df_oneday = df_date.get_group(date) # df of one day\n",
    "        dfh = df_oneday.groupby('hour').sum()\n",
    "        dfh = dfh.drop(['year', 'month', 'user_id', 'RT_flag', 'day'],axis=1)\n",
    "\n",
    "        # Save csv\n",
    "        outname = filetype+str(date)+'.csv'\n",
    "        savename = os.path.join(outdir, outname)\n",
    "\n",
    "        if os.path.exists(savename):\n",
    "            # File1\n",
    "            existedfile = pd.read_csv(savename)\n",
    "            # いったんcsvにする\n",
    "            _saveonce = 'once.csv'\n",
    "            dfh.to_csv(_saveonce)\n",
    "            # File2 \n",
    "            once = pd.read_csv(_saveonce)\n",
    "            # Concat \n",
    "            df_oneday1 = pd.concat([existedfile, once], axis=0)\n",
    "            # Finally save\n",
    "            dfh = df_oneday1.groupby('hour').sum()\n",
    "\n",
    "        # Save to csv\n",
    "        dfh.to_csv(savename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "10it [01:32,  9.22s/it]\n"
     ]
    }
   ],
   "source": [
    "# Orjp\n",
    "filetypes = ['C']\n",
    "# filetypes = ['D', 'A', 'V', 'F', 'C']\n",
    "for filetype in filetypes:\n",
    "    findtwt_hour(dfors, filetype=filetype, savedir='testV4hour', key_lang='jp', filt_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('testV4hour/V2020-03-15.csv')\n",
    "real = pd.read_csv('../new_results_jst2/orjp/day/V4b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2985"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.loc[14, 'V4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2985.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.V4.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>V4b</th>\n",
       "      <th>V4b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  V4b     V4b\n",
       "0   NaN  NaN     0.0\n",
       "1   NaN  NaN    -2.0\n",
       "2   NaN  NaN     0.0\n",
       "3   NaN  NaN    -2.0\n",
       "4   NaN  NaN    -1.0\n",
       "5   NaN  NaN     0.0\n",
       "6   NaN  NaN    -1.0\n",
       "7   NaN  NaN    -1.0\n",
       "8   NaN  NaN    -2.0\n",
       "9   NaN  NaN    -4.0\n",
       "10  NaN  NaN    -1.0\n",
       "11  NaN  NaN     0.0\n",
       "12  NaN  NaN    -1.0\n",
       "13  NaN  NaN    -1.0\n",
       "14  NaN  NaN     0.0\n",
       "15  NaN  NaN -8465.0\n",
       "16  NaN  NaN     0.0\n",
       "17  NaN  NaN    -2.0\n",
       "18  NaN  NaN     0.0\n",
       "19  NaN  NaN     0.0\n",
       "20  NaN  NaN     0.0\n",
       "21  NaN  NaN    -1.0\n",
       "22  NaN  NaN     0.0\n",
       "23  NaN  NaN    -1.0\n",
       "24  NaN  NaN    -1.0\n",
       "25  NaN  NaN    -1.0\n",
       "26  NaN  NaN    -1.0\n",
       "27  NaN  NaN     0.0\n",
       "28  NaN  NaN     0.0\n",
       "29  NaN  NaN    -1.0\n",
       "30  NaN  NaN    -2.0\n",
       "31  NaN  NaN     0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../new_results2/orjp/day/'\n",
    "a = pd.read_csv(path+'V4a.csv').rename(columns={'V4': 'V4b'})\n",
    "b = pd.read_csv(path+'V4b.csv').rename(columns={'V4': 'V4b'})\n",
    "\n",
    "d = pd.concat([a, b.V4b], axis =1, join='inner')\n",
    "d.diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([a, b.V4b], axis =1, join='inner')\n",
    "d.diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>V4b</th>\n",
       "      <th>V4b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date  V4b  V4b\n",
       "0   NaN  NaN  0.0\n",
       "1   NaN  NaN  0.0\n",
       "2   NaN  NaN -2.0\n",
       "3   NaN  NaN  0.0\n",
       "4   NaN  NaN  0.0\n",
       "5   NaN  NaN  0.0\n",
       "6   NaN  NaN  0.0\n",
       "7   NaN  NaN  0.0\n",
       "8   NaN  NaN  0.0\n",
       "9   NaN  NaN  0.0\n",
       "10  NaN  NaN -1.0\n",
       "11  NaN  NaN  0.0\n",
       "12  NaN  NaN  0.0\n",
       "13  NaN  NaN  0.0\n",
       "14  NaN  NaN  0.0\n",
       "15  NaN  NaN  0.0\n",
       "16  NaN  NaN  0.0\n",
       "17  NaN  NaN  0.0\n",
       "18  NaN  NaN  0.0\n",
       "19  NaN  NaN  0.0\n",
       "20  NaN  NaN  0.0\n",
       "21  NaN  NaN  0.0\n",
       "22  NaN  NaN  0.0\n",
       "23  NaN  NaN -1.0\n",
       "24  NaN  NaN  0.0\n",
       "25  NaN  NaN  0.0\n",
       "26  NaN  NaN  0.0\n",
       "27  NaN  NaN  0.0\n",
       "28  NaN  NaN  0.0\n",
       "29  NaN  NaN  0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.diff(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>RT_flag</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>time</th>\n",
       "      <th>C12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188412</th>\n",
       "      <td>3151155025</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>「桜の森の満開のあとで」昨日観劇。すぐには感想がまとまらないくらい、見応えのある演劇で放心状...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>20:56:24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102728</th>\n",
       "      <td>1092751135528562689</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>リコも直輝も選択が切なすぎて、未だに放心状態。涙が止まらない。考えも、まとまらない。だけど、...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>23:38:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680640</th>\n",
       "      <td>1213074071849553930</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>観終わって30分くらいたっても、動けない、放心状態、初めての感覚、衝撃、なんて言って良いのか...</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>23:46:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id        date  \\\n",
       "188412           3151155025  2020-03-18   \n",
       "102728  1092751135528562689  2020-03-15   \n",
       "680640  1213074071849553930  2020-03-10   \n",
       "\n",
       "                                                    tweet  RT_flag  year  \\\n",
       "188412  「桜の森の満開のあとで」昨日観劇。すぐには感想がまとまらないくらい、見応えのある演劇で放心状...    False  2020   \n",
       "102728  リコも直輝も選択が切なすぎて、未だに放心状態。涙が止まらない。考えも、まとまらない。だけど、...    False  2020   \n",
       "680640  観終わって30分くらいたっても、動けない、放心状態、初めての感覚、衝撃、なんて言って良いのか...    False  2020   \n",
       "\n",
       "        month  day  hour      time  C12  \n",
       "188412      3   18    20  20:56:24    1  \n",
       "102728      3   15    23  23:38:23    1  \n",
       "680640      3   10    23  23:46:41    1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4_without_eroi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
