{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import ijson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:1127.6700174808502[sec]\n",
      "elapsed_time:707.399224281311[sec]\n"
     ]
    }
   ],
   "source": [
    "# jsons = ['../data/part_v003_o001_r_00001.json']\n",
    "jsons = ['../data/part_v003_o001_r_00000.json', '../data/part_v003_o001_r_00001.json']\n",
    "\n",
    "dfrts = []\n",
    "dfors = []\n",
    "for json in jsons:\n",
    "    # Instance Preparation\n",
    "    dates = []\n",
    "    tweets = []\n",
    "    \n",
    "    start = time.time()\n",
    "    # Load json file: date and tweet\n",
    "    with open(json, 'r') as file:\n",
    "        pet_parse = ijson.parse(file, multiple_values=True)\n",
    "        for prefix, event, value  in pet_parse:\n",
    "            if prefix == 'created_at':\n",
    "                dates.append(datetime.strptime(value, '%a %b %d %H:%M:%S +0000 %Y'))\n",
    "            if prefix == 'text':\n",
    "                tweets.append(value)\n",
    "    print (\"Loadinf json elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n",
    "    \n",
    "    # Df\n",
    "    data = np.vstack([dates, tweets]).T\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['date', 'tweet'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['date'] = df['date'].dt.date\n",
    "    df['RT_flag'] = df['tweet'].str.contains('RT') # True if tweet containt 'RT', otherwise False\n",
    "\n",
    "    # divide df by Original tweet and RT \n",
    "    dfrt = df[df['RT_flag'] == True]\n",
    "    dfor = df[df['RT_flag'] == False]\n",
    "    \n",
    "    dfrts.append(dfor)\n",
    "    dfors.append(dfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[               date                                              tweet  year  \\\n",
       " 1        2020-02-29  今夜は久しぶりに \\nお月様を見れましたが、\\n少し雲がかかって\\nボンヤリ月でした\\n☁🌛...  2020   \n",
       " 2        2020-02-29   長期的にはジャイロに慣れた方が良いんだけど、今回の大会しか見てないのかなってちょっと悲しくなった  2020   \n",
       " 3        2020-02-29               不二先輩の誕生日で言いたいことたくさんあるけど、上手くまとまらないね😭😭  2020   \n",
       " 5        2020-02-29  フェルナンドと遊ぼう\\n・華麗なるフェルナンド\\n・フェルナンドの憂鬱\\n・翔べフェルナンド...  2020   \n",
       " 10       2020-02-29  @takukuroneko BLEEDは1の哀しいストーリーを見事に表現してるところが良いで...  2020   \n",
       " ...             ...                                                ...   ...   \n",
       " 2057678  2020-02-26  ４０を過ぎたオジサンだけど孤独…\\n誰かつながって…\\n\\n#依存\\n#共依存\\n#独占欲\\...  2020   \n",
       " 2057679  2020-02-26  仕方ないので1回父親の脛蹴ってからめっちゃしょんぼりしてる弟なだめて不機嫌な父親無視してその...  2020   \n",
       " 2057680  2020-02-26                                            孤独にないた獣  2020   \n",
       " 2057682  2020-02-26            俺もそう思った。どうやら模擬戦をしていたようだが、ずいぶんと不機嫌な様子だった  2020   \n",
       " 2057684  2020-02-26  @ota_katu5 そ、なー！（それな\\n曖昧すぎやし\\n世論のこの空気嫌やわ\\n無関係の...  2020   \n",
       " \n",
       "          month  day  hour  RT_flag  \n",
       " 1            2   29    14    False  \n",
       " 2            2   29    14    False  \n",
       " 3            2   29    14    False  \n",
       " 5            2   29    14    False  \n",
       " 10           2   29    14    False  \n",
       " ...        ...  ...   ...      ...  \n",
       " 2057678      2   26    17    False  \n",
       " 2057679      2   26    17    False  \n",
       " 2057680      2   26    17    False  \n",
       " 2057682      2   26    17    False  \n",
       " 2057684      2   26    17    False  \n",
       " \n",
       " [965750 rows x 7 columns],\n",
       "                date                                              tweet  year  \\\n",
       " 0        2020-02-26  悲しくて記憶が曖昧だけどアレク様が最後に\\n「一度しか言わないからよく聞け。俺の名前は大和ア...  2020   \n",
       " 1        2020-02-26  @Yeonjun__3 え～～～～まじですか！？！そんなの言ってもらって嬉しいです🥺‼ずっと...  2020   \n",
       " 3        2020-02-26  新しい相互できたときタイムラインに新しい名前があって2ヶ月くらいそわそわするしお迎えに行って...  2020   \n",
       " 4        2020-02-26  ガチッマチウデマエが上がらなくて失望していたときにオクト買ったからその時はいい気分転換になっ...  2020   \n",
       " 5        2020-02-26  自分から飛び込んだ世界。\\nでもいつの間にかその世界でしか生きれなくなってた。\\nその世界か...  2020   \n",
       " ...             ...                                                ...   ...   \n",
       " 1512933  2020-02-23  @LKqQ0O2tEPMHupc @noiepoie @yumidesu_4649 @Abe...  2020   \n",
       " 1512935  2020-02-23  iPadAir2から新型iPad Proに買い換えて困った事と、その解決方法について書きまし...  2020   \n",
       " 1512936  2020-02-23  私はうんざりもできない。無知を嘲笑うのも嫌だし、勉強しないことを非難するのも嫌だし、最大多数...  2020   \n",
       " 1512937  2020-02-23  自分のことばかりいつも主張して 君の言葉なら上の空で聞いて ギターを弾いてた ぼんやりといつ...  2020   \n",
       " 1512942  2020-02-23  薬飲んだから酷くはないものの不安感は消えず、朝起きて薬の効果が切れたらきっとまた不安感に襲わ...  2020   \n",
       " \n",
       "          month  day  hour  RT_flag  \n",
       " 0            2   26    17    False  \n",
       " 1            2   26    17    False  \n",
       " 3            2   26    17    False  \n",
       " 4            2   26    17    False  \n",
       " 5            2   26    17    False  \n",
       " ...        ...  ...   ...      ...  \n",
       " 1512933      2   23    19    False  \n",
       " 1512935      2   23    19    False  \n",
       " 1512936      2   23    19    False  \n",
       " 1512937      2   23    19    False  \n",
       " 1512942      2   23    19    False  \n",
       " \n",
       " [862546 rows x 7 columns]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filetypes = ['T', 'D', 'A', 'V', 'F', 'C']\n",
    "def findtwt(dfors, filetype=\"C\"):\n",
    "    # Prepartion of dfw \n",
    "    results = []\n",
    "    dfs = []\n",
    "    dfw = pd.read_csv('../data/WordTimeSeries.csv', encoding='utf-8').rename(columns={'Unnamed: 0': 'types',\n",
    "                                                                                    'file name': 'file_name', \n",
    "                                                                                    'orignal form': 'orignal_form',\n",
    "                                                                                    'English translation': 'English_translation'})\n",
    "    booleanDictionary = {True: 'TRUE', False: 'FALSE'} # Drop nan and False in order to use query \n",
    "    dfw = dfw.replace(booleanDictionary)\n",
    "    dfw = dfw.dropna(how='all')\n",
    "    \n",
    "    # Prepration of keywords\n",
    "    filenames = [filename for filename in dfw.file_name.tolist() if filetype in filename]\n",
    "    xd = {}\n",
    "    xd['T'] = 'file_name.str.contains(\"T\")'\n",
    "    xd['D'] = 'file_name.str.contains(\"D\")'\n",
    "    xd['A'] = 'file_name.str.contains(\"A\")'\n",
    "    xd['V'] = 'file_name.str.contains(\"V\")'\n",
    "    xd['F'] = 'file_name.str.contains(\"F\")'\n",
    "    xd['C'] = 'file_name.str.contains(\"C\")'\n",
    "    \n",
    "    query = xd[filetype]\n",
    "    dfw_c = dfw.query(query, engine='python')\n",
    "    keywords = dfw_c.orignal_form.tolist() # English.ver: keywords = dfw_c.English_translation.tolist() \n",
    "    \n",
    "    # Find tweets\n",
    "    for dfor in dfors:\n",
    "        # Extract tweet\n",
    "        dfor_c = dfor[dfor['tweet'].str.contains('|'.join(keywords))]\n",
    "        \n",
    "        for col, key in zip(filenames, keywords):\n",
    "            l = []\n",
    "            for row in dfor_c.itertuples():\n",
    "                if key in row.tweet:\n",
    "                    l.append(1)\n",
    "                else:\n",
    "                    l.append(0)\n",
    "            dfor_c[col] = l\n",
    "        \n",
    "        # Make rows\n",
    "        uni_dates = dfor_c['date'].tolist()\n",
    "        uni_dates = sorted(set(uni_dates), key=uni_dates.index) # date values\n",
    "        rows = []\n",
    "        for date in uni_dates:\n",
    "            d = {}\n",
    "            d['date'] = str(date)\n",
    "            for col in filenames:\n",
    "                _df = dfor_c.groupby('date').get_group(date)\n",
    "                d[col] = _df[col].sum()\n",
    "            rows.append(d)\n",
    "        \n",
    "        # Make cols\n",
    "        cols = filenames.copy()\n",
    "        cols.insert(0, 'date')\n",
    "        \n",
    "        # Make dfs with rows and cols\n",
    "        dft = pd.DataFrame(columns=cols)\n",
    "        for row in rows:\n",
    "            dft = dft.append(row, ignore_index=True)\n",
    "        \n",
    "        dfs.append(dft)\n",
    "\n",
    "    # Finally Connect dfs\n",
    "    for i, df in enumerate(dfs):\n",
    "        if i == 0:\n",
    "            dfnew = df\n",
    "        else:\n",
    "            dfnew = pd.concat([dfnew, df], axis=0)\n",
    "            \n",
    "    # Groupby and sort by date\n",
    "    dfnew = dfnew.groupby('date').sum()\n",
    "    \n",
    "    return dfnew\n",
    "\n",
    "# dfnew = findtwt(dfors, filetype=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "      <th>T21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>673</td>\n",
       "      <td>486</td>\n",
       "      <td>196</td>\n",
       "      <td>402</td>\n",
       "      <td>699</td>\n",
       "      <td>218</td>\n",
       "      <td>466</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24</th>\n",
       "      <td>7752</td>\n",
       "      <td>4876</td>\n",
       "      <td>3246</td>\n",
       "      <td>5651</td>\n",
       "      <td>9406</td>\n",
       "      <td>2829</td>\n",
       "      <td>6654</td>\n",
       "      <td>3283</td>\n",
       "      <td>3420</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>111</td>\n",
       "      <td>328</td>\n",
       "      <td>157</td>\n",
       "      <td>488</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>128</td>\n",
       "      <td>317</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25</th>\n",
       "      <td>9122</td>\n",
       "      <td>6238</td>\n",
       "      <td>3479</td>\n",
       "      <td>5210</td>\n",
       "      <td>11693</td>\n",
       "      <td>3362</td>\n",
       "      <td>7785</td>\n",
       "      <td>3371</td>\n",
       "      <td>3462</td>\n",
       "      <td>585</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>104</td>\n",
       "      <td>293</td>\n",
       "      <td>148</td>\n",
       "      <td>561</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>131</td>\n",
       "      <td>317</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-26</th>\n",
       "      <td>10608</td>\n",
       "      <td>5316</td>\n",
       "      <td>3950</td>\n",
       "      <td>4863</td>\n",
       "      <td>13843</td>\n",
       "      <td>4025</td>\n",
       "      <td>9274</td>\n",
       "      <td>3422</td>\n",
       "      <td>3625</td>\n",
       "      <td>784</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>164</td>\n",
       "      <td>299</td>\n",
       "      <td>148</td>\n",
       "      <td>631</td>\n",
       "      <td>75</td>\n",
       "      <td>48</td>\n",
       "      <td>153</td>\n",
       "      <td>318</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27</th>\n",
       "      <td>11899</td>\n",
       "      <td>6469</td>\n",
       "      <td>4443</td>\n",
       "      <td>4547</td>\n",
       "      <td>14894</td>\n",
       "      <td>5059</td>\n",
       "      <td>10891</td>\n",
       "      <td>3741</td>\n",
       "      <td>3708</td>\n",
       "      <td>790</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>161</td>\n",
       "      <td>271</td>\n",
       "      <td>137</td>\n",
       "      <td>677</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>324</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28</th>\n",
       "      <td>10102</td>\n",
       "      <td>6501</td>\n",
       "      <td>4644</td>\n",
       "      <td>4318</td>\n",
       "      <td>12666</td>\n",
       "      <td>4694</td>\n",
       "      <td>10539</td>\n",
       "      <td>3584</td>\n",
       "      <td>3628</td>\n",
       "      <td>749</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>144</td>\n",
       "      <td>263</td>\n",
       "      <td>145</td>\n",
       "      <td>572</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>138</td>\n",
       "      <td>306</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>7104</td>\n",
       "      <td>2907</td>\n",
       "      <td>3324</td>\n",
       "      <td>4431</td>\n",
       "      <td>8268</td>\n",
       "      <td>3120</td>\n",
       "      <td>7229</td>\n",
       "      <td>2917</td>\n",
       "      <td>3645</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>104</td>\n",
       "      <td>259</td>\n",
       "      <td>117</td>\n",
       "      <td>405</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>126</td>\n",
       "      <td>246</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               T1    T2    T3    T4     T5    T6     T7    T8    T9  T10  ...  \\\n",
       "date                                                                      ...   \n",
       "2020-02-23    673   486   196   402    699   218    466   206   208   40  ...   \n",
       "2020-02-24   7752  4876  3246  5651   9406  2829   6654  3283  3420  518  ...   \n",
       "2020-02-25   9122  6238  3479  5210  11693  3362   7785  3371  3462  585  ...   \n",
       "2020-02-26  10608  5316  3950  4863  13843  4025   9274  3422  3625  784  ...   \n",
       "2020-02-27  11899  6469  4443  4547  14894  5059  10891  3741  3708  790  ...   \n",
       "2020-02-28  10102  6501  4644  4318  12666  4694  10539  3584  3628  749  ...   \n",
       "2020-02-29   7104  2907  3324  4431   8268  3120   7229  2917  3645  416  ...   \n",
       "\n",
       "            T12  T13  T14  T15  T16  T17  T18  T19  T20  T21  \n",
       "date                                                          \n",
       "2020-02-23   10    9   33   17   34    6    3   19   23   16  \n",
       "2020-02-24  139  111  328  157  488   41   60  128  317  160  \n",
       "2020-02-25  137  104  293  148  561   45   60  131  317  135  \n",
       "2020-02-26  189  164  299  148  631   75   48  153  318  122  \n",
       "2020-02-27  218  161  271  137  677   77   55  176  324  137  \n",
       "2020-02-28  250  144  263  145  572   62   58  138  306  140  \n",
       "2020-02-29  181  104  259  117  405   55   47  126  246  114  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "outname = 'c_original.csv'\n",
    "outdir = '../results/jp'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "savename = os.path.join(outdir, outname)    \n",
    "\n",
    "dft.to_csv(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "outname = 'c_original.csv'\n",
    "outdir = '../results/jp/day'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "fullname = os.path.join(outdir, outname)    \n",
    "\n",
    "dft.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
