{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "from datetime import datetime\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import ijson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:1127.6700174808502[sec]\n",
      "elapsed_time:707.399224281311[sec]\n"
     ]
    }
   ],
   "source": [
    "# jsons = ['../data/part_v003_o001_r_00001.json']\n",
    "jsons = ['../data/part_v003_o001_r_00000.json', '../data/part_v003_o001_r_00001.json']\n",
    "\n",
    "dfrts = []\n",
    "dfors = []\n",
    "for json in jsons:\n",
    "    # Instance Preparation\n",
    "    dates = []\n",
    "    tweets = []\n",
    "    \n",
    "    start = time.time()\n",
    "    # Load json file: date and tweet\n",
    "    with open(json, 'r') as file:\n",
    "        pet_parse = ijson.parse(file, multiple_values=True)\n",
    "        for prefix, event, value  in pet_parse:\n",
    "            if prefix == 'created_at':\n",
    "                dates.append(datetime.strptime(value, '%a %b %d %H:%M:%S +0000 %Y'))\n",
    "            if prefix == 'text':\n",
    "                tweets.append(value)\n",
    "    print (\"Loadinf json elapsed_time:{0}\".format(time.time() - start) + \"[sec]\")\n",
    "    \n",
    "    # Df\n",
    "    data = np.vstack([dates, tweets]).T\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['date', 'tweet'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['date'] = df['date'].dt.date\n",
    "    df['RT_flag'] = df['tweet'].str.contains('RT') # True if tweet containt 'RT', otherwise False\n",
    "\n",
    "    # divide df by Original tweet and RT \n",
    "    dfrt = df[df['RT_flag'] == True]\n",
    "    dfor = df[df['RT_flag'] == False]\n",
    "    \n",
    "    dfrts.append(dfor)\n",
    "    dfors.append(dfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[               date                                              tweet  year  \\\n",
       " 1        2020-02-29  ä»Šå¤œã¯ä¹…ã—ã¶ã‚Šã« \\nãŠæœˆæ§˜ã‚’è¦‹ã‚Œã¾ã—ãŸãŒã€\\nå°‘ã—é›²ãŒã‹ã‹ã£ã¦\\nãƒœãƒ³ãƒ¤ãƒªæœˆã§ã—ãŸ\\nâ˜ğŸŒ›...  2020   \n",
       " 2        2020-02-29   é•·æœŸçš„ã«ã¯ã‚¸ãƒ£ã‚¤ãƒ­ã«æ…£ã‚ŒãŸæ–¹ãŒè‰¯ã„ã‚“ã ã‘ã©ã€ä»Šå›ã®å¤§ä¼šã—ã‹è¦‹ã¦ãªã„ã®ã‹ãªã£ã¦ã¡ã‚‡ã£ã¨æ‚²ã—ããªã£ãŸ  2020   \n",
       " 3        2020-02-29               ä¸äºŒå…ˆè¼©ã®èª•ç”Ÿæ—¥ã§è¨€ã„ãŸã„ã“ã¨ãŸãã•ã‚“ã‚ã‚‹ã‘ã©ã€ä¸Šæ‰‹ãã¾ã¨ã¾ã‚‰ãªã„ã­ğŸ˜­ğŸ˜­  2020   \n",
       " 5        2020-02-29  ãƒ•ã‚§ãƒ«ãƒŠãƒ³ãƒ‰ã¨éŠã¼ã†\\nãƒ»è¯éº—ãªã‚‹ãƒ•ã‚§ãƒ«ãƒŠãƒ³ãƒ‰\\nãƒ»ãƒ•ã‚§ãƒ«ãƒŠãƒ³ãƒ‰ã®æ†‚é¬±\\nãƒ»ç¿”ã¹ãƒ•ã‚§ãƒ«ãƒŠãƒ³ãƒ‰...  2020   \n",
       " 10       2020-02-29  @takukuroneko BLEEDã¯1ã®å“€ã—ã„ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’è¦‹äº‹ã«è¡¨ç¾ã—ã¦ã‚‹ã¨ã“ã‚ãŒè‰¯ã„ã§...  2020   \n",
       " ...             ...                                                ...   ...   \n",
       " 2057678  2020-02-26  ï¼”ï¼ã‚’éããŸã‚ªã‚¸ã‚µãƒ³ã ã‘ã©å­¤ç‹¬â€¦\\nèª°ã‹ã¤ãªãŒã£ã¦â€¦\\n\\n#ä¾å­˜\\n#å…±ä¾å­˜\\n#ç‹¬å æ¬²\\...  2020   \n",
       " 2057679  2020-02-26  ä»•æ–¹ãªã„ã®ã§1å›çˆ¶è¦ªã®è„›è¹´ã£ã¦ã‹ã‚‰ã‚ã£ã¡ã‚ƒã—ã‚‡ã‚“ã¼ã‚Šã—ã¦ã‚‹å¼Ÿãªã ã‚ã¦ä¸æ©Ÿå«Œãªçˆ¶è¦ªç„¡è¦–ã—ã¦ãã®...  2020   \n",
       " 2057680  2020-02-26                                            å­¤ç‹¬ã«ãªã„ãŸç£  2020   \n",
       " 2057682  2020-02-26            ä¿ºã‚‚ãã†æ€ã£ãŸã€‚ã©ã†ã‚„ã‚‰æ¨¡æ“¬æˆ¦ã‚’ã—ã¦ã„ãŸã‚ˆã†ã ãŒã€ãšã„ã¶ã‚“ã¨ä¸æ©Ÿå«Œãªæ§˜å­ã ã£ãŸ  2020   \n",
       " 2057684  2020-02-26  @ota_katu5 ãã€ãªãƒ¼ï¼ï¼ˆãã‚Œãª\\næ›–æ˜§ã™ãã‚„ã—\\nä¸–è«–ã®ã“ã®ç©ºæ°—å«Œã‚„ã‚\\nç„¡é–¢ä¿‚ã®...  2020   \n",
       " \n",
       "          month  day  hour  RT_flag  \n",
       " 1            2   29    14    False  \n",
       " 2            2   29    14    False  \n",
       " 3            2   29    14    False  \n",
       " 5            2   29    14    False  \n",
       " 10           2   29    14    False  \n",
       " ...        ...  ...   ...      ...  \n",
       " 2057678      2   26    17    False  \n",
       " 2057679      2   26    17    False  \n",
       " 2057680      2   26    17    False  \n",
       " 2057682      2   26    17    False  \n",
       " 2057684      2   26    17    False  \n",
       " \n",
       " [965750 rows x 7 columns],\n",
       "                date                                              tweet  year  \\\n",
       " 0        2020-02-26  æ‚²ã—ãã¦è¨˜æ†¶ãŒæ›–æ˜§ã ã‘ã©ã‚¢ãƒ¬ã‚¯æ§˜ãŒæœ€å¾Œã«\\nã€Œä¸€åº¦ã—ã‹è¨€ã‚ãªã„ã‹ã‚‰ã‚ˆãèã‘ã€‚ä¿ºã®åå‰ã¯å¤§å’Œã‚¢...  2020   \n",
       " 1        2020-02-26  @Yeonjun__3 ãˆï½ï½ï½ï½ã¾ã˜ã§ã™ã‹ï¼ï¼Ÿï¼ãã‚“ãªã®è¨€ã£ã¦ã‚‚ã‚‰ã£ã¦å¬‰ã—ã„ã§ã™ğŸ¥ºâ€¼ãšã£ã¨...  2020   \n",
       " 3        2020-02-26  æ–°ã—ã„ç›¸äº’ã§ããŸã¨ãã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«æ–°ã—ã„åå‰ãŒã‚ã£ã¦2ãƒ¶æœˆãã‚‰ã„ãã‚ãã‚ã™ã‚‹ã—ãŠè¿ãˆã«è¡Œã£ã¦...  2020   \n",
       " 4        2020-02-26  ã‚¬ãƒãƒƒãƒãƒã‚¦ãƒ‡ãƒã‚¨ãŒä¸ŠãŒã‚‰ãªãã¦å¤±æœ›ã—ã¦ã„ãŸã¨ãã«ã‚ªã‚¯ãƒˆè²·ã£ãŸã‹ã‚‰ãã®æ™‚ã¯ã„ã„æ°—åˆ†è»¢æ›ã«ãªã£...  2020   \n",
       " 5        2020-02-26  è‡ªåˆ†ã‹ã‚‰é£›ã³è¾¼ã‚“ã ä¸–ç•Œã€‚\\nã§ã‚‚ã„ã¤ã®é–“ã«ã‹ãã®ä¸–ç•Œã§ã—ã‹ç”Ÿãã‚Œãªããªã£ã¦ãŸã€‚\\nãã®ä¸–ç•Œã‹...  2020   \n",
       " ...             ...                                                ...   ...   \n",
       " 1512933  2020-02-23  @LKqQ0O2tEPMHupc @noiepoie @yumidesu_4649 @Abe...  2020   \n",
       " 1512935  2020-02-23  iPadAir2ã‹ã‚‰æ–°å‹iPad Proã«è²·ã„æ›ãˆã¦å›°ã£ãŸäº‹ã¨ã€ãã®è§£æ±ºæ–¹æ³•ã«ã¤ã„ã¦æ›¸ãã¾ã—...  2020   \n",
       " 1512936  2020-02-23  ç§ã¯ã†ã‚“ã–ã‚Šã‚‚ã§ããªã„ã€‚ç„¡çŸ¥ã‚’å˜²ç¬‘ã†ã®ã‚‚å«Œã ã—ã€å‹‰å¼·ã—ãªã„ã“ã¨ã‚’éé›£ã™ã‚‹ã®ã‚‚å«Œã ã—ã€æœ€å¤§å¤šæ•°...  2020   \n",
       " 1512937  2020-02-23  è‡ªåˆ†ã®ã“ã¨ã°ã‹ã‚Šã„ã¤ã‚‚ä¸»å¼µã—ã¦ å›ã®è¨€è‘‰ãªã‚‰ä¸Šã®ç©ºã§èã„ã¦ ã‚®ã‚¿ãƒ¼ã‚’å¼¾ã„ã¦ãŸ ã¼ã‚“ã‚„ã‚Šã¨ã„ã¤...  2020   \n",
       " 1512942  2020-02-23  è–¬é£²ã‚“ã ã‹ã‚‰é…·ãã¯ãªã„ã‚‚ã®ã®ä¸å®‰æ„Ÿã¯æ¶ˆãˆãšã€æœèµ·ãã¦è–¬ã®åŠ¹æœãŒåˆ‡ã‚ŒãŸã‚‰ãã£ã¨ã¾ãŸä¸å®‰æ„Ÿã«è¥²ã‚...  2020   \n",
       " \n",
       "          month  day  hour  RT_flag  \n",
       " 0            2   26    17    False  \n",
       " 1            2   26    17    False  \n",
       " 3            2   26    17    False  \n",
       " 4            2   26    17    False  \n",
       " 5            2   26    17    False  \n",
       " ...        ...  ...   ...      ...  \n",
       " 1512933      2   23    19    False  \n",
       " 1512935      2   23    19    False  \n",
       " 1512936      2   23    19    False  \n",
       " 1512937      2   23    19    False  \n",
       " 1512942      2   23    19    False  \n",
       " \n",
       " [862546 rows x 7 columns]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filetypes = ['T', 'D', 'A', 'V', 'F', 'C']\n",
    "def findtwt(dfors, filetype=\"C\"):\n",
    "    # Prepartion of dfw \n",
    "    results = []\n",
    "    dfs = []\n",
    "    dfw = pd.read_csv('../data/WordTimeSeries.csv', encoding='utf-8').rename(columns={'Unnamed: 0': 'types',\n",
    "                                                                                    'file name': 'file_name', \n",
    "                                                                                    'orignal form': 'orignal_form',\n",
    "                                                                                    'English translation': 'English_translation'})\n",
    "    booleanDictionary = {True: 'TRUE', False: 'FALSE'} # Drop nan and False in order to use query \n",
    "    dfw = dfw.replace(booleanDictionary)\n",
    "    dfw = dfw.dropna(how='all')\n",
    "    \n",
    "    # Prepration of keywords\n",
    "    filenames = [filename for filename in dfw.file_name.tolist() if filetype in filename]\n",
    "    xd = {}\n",
    "    xd['T'] = 'file_name.str.contains(\"T\")'\n",
    "    xd['D'] = 'file_name.str.contains(\"D\")'\n",
    "    xd['A'] = 'file_name.str.contains(\"A\")'\n",
    "    xd['V'] = 'file_name.str.contains(\"V\")'\n",
    "    xd['F'] = 'file_name.str.contains(\"F\")'\n",
    "    xd['C'] = 'file_name.str.contains(\"C\")'\n",
    "    \n",
    "    query = xd[filetype]\n",
    "    dfw_c = dfw.query(query, engine='python')\n",
    "    keywords = dfw_c.orignal_form.tolist() # English.ver: keywords = dfw_c.English_translation.tolist() \n",
    "    \n",
    "    # Find tweets\n",
    "    for dfor in dfors:\n",
    "        # Extract tweet\n",
    "        dfor_c = dfor[dfor['tweet'].str.contains('|'.join(keywords))]\n",
    "        \n",
    "        for col, key in zip(filenames, keywords):\n",
    "            l = []\n",
    "            for row in dfor_c.itertuples():\n",
    "                if key in row.tweet:\n",
    "                    l.append(1)\n",
    "                else:\n",
    "                    l.append(0)\n",
    "            dfor_c[col] = l\n",
    "        \n",
    "        # Make rows\n",
    "        uni_dates = dfor_c['date'].tolist()\n",
    "        uni_dates = sorted(set(uni_dates), key=uni_dates.index) # date values\n",
    "        rows = []\n",
    "        for date in uni_dates:\n",
    "            d = {}\n",
    "            d['date'] = str(date)\n",
    "            for col in filenames:\n",
    "                _df = dfor_c.groupby('date').get_group(date)\n",
    "                d[col] = _df[col].sum()\n",
    "            rows.append(d)\n",
    "        \n",
    "        # Make cols\n",
    "        cols = filenames.copy()\n",
    "        cols.insert(0, 'date')\n",
    "        \n",
    "        # Make dfs with rows and cols\n",
    "        dft = pd.DataFrame(columns=cols)\n",
    "        for row in rows:\n",
    "            dft = dft.append(row, ignore_index=True)\n",
    "        \n",
    "        dfs.append(dft)\n",
    "\n",
    "    # Finally Connect dfs\n",
    "    for i, df in enumerate(dfs):\n",
    "        if i == 0:\n",
    "            dfnew = df\n",
    "        else:\n",
    "            dfnew = pd.concat([dfnew, df], axis=0)\n",
    "            \n",
    "    # Groupby and sort by date\n",
    "    dfnew = dfnew.groupby('date').sum()\n",
    "    \n",
    "    return dfnew\n",
    "\n",
    "# dfnew = findtwt(dfors, filetype=\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "      <th>T21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>673</td>\n",
       "      <td>486</td>\n",
       "      <td>196</td>\n",
       "      <td>402</td>\n",
       "      <td>699</td>\n",
       "      <td>218</td>\n",
       "      <td>466</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-24</th>\n",
       "      <td>7752</td>\n",
       "      <td>4876</td>\n",
       "      <td>3246</td>\n",
       "      <td>5651</td>\n",
       "      <td>9406</td>\n",
       "      <td>2829</td>\n",
       "      <td>6654</td>\n",
       "      <td>3283</td>\n",
       "      <td>3420</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>111</td>\n",
       "      <td>328</td>\n",
       "      <td>157</td>\n",
       "      <td>488</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>128</td>\n",
       "      <td>317</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-25</th>\n",
       "      <td>9122</td>\n",
       "      <td>6238</td>\n",
       "      <td>3479</td>\n",
       "      <td>5210</td>\n",
       "      <td>11693</td>\n",
       "      <td>3362</td>\n",
       "      <td>7785</td>\n",
       "      <td>3371</td>\n",
       "      <td>3462</td>\n",
       "      <td>585</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>104</td>\n",
       "      <td>293</td>\n",
       "      <td>148</td>\n",
       "      <td>561</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>131</td>\n",
       "      <td>317</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-26</th>\n",
       "      <td>10608</td>\n",
       "      <td>5316</td>\n",
       "      <td>3950</td>\n",
       "      <td>4863</td>\n",
       "      <td>13843</td>\n",
       "      <td>4025</td>\n",
       "      <td>9274</td>\n",
       "      <td>3422</td>\n",
       "      <td>3625</td>\n",
       "      <td>784</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>164</td>\n",
       "      <td>299</td>\n",
       "      <td>148</td>\n",
       "      <td>631</td>\n",
       "      <td>75</td>\n",
       "      <td>48</td>\n",
       "      <td>153</td>\n",
       "      <td>318</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27</th>\n",
       "      <td>11899</td>\n",
       "      <td>6469</td>\n",
       "      <td>4443</td>\n",
       "      <td>4547</td>\n",
       "      <td>14894</td>\n",
       "      <td>5059</td>\n",
       "      <td>10891</td>\n",
       "      <td>3741</td>\n",
       "      <td>3708</td>\n",
       "      <td>790</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>161</td>\n",
       "      <td>271</td>\n",
       "      <td>137</td>\n",
       "      <td>677</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>324</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28</th>\n",
       "      <td>10102</td>\n",
       "      <td>6501</td>\n",
       "      <td>4644</td>\n",
       "      <td>4318</td>\n",
       "      <td>12666</td>\n",
       "      <td>4694</td>\n",
       "      <td>10539</td>\n",
       "      <td>3584</td>\n",
       "      <td>3628</td>\n",
       "      <td>749</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>144</td>\n",
       "      <td>263</td>\n",
       "      <td>145</td>\n",
       "      <td>572</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>138</td>\n",
       "      <td>306</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29</th>\n",
       "      <td>7104</td>\n",
       "      <td>2907</td>\n",
       "      <td>3324</td>\n",
       "      <td>4431</td>\n",
       "      <td>8268</td>\n",
       "      <td>3120</td>\n",
       "      <td>7229</td>\n",
       "      <td>2917</td>\n",
       "      <td>3645</td>\n",
       "      <td>416</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>104</td>\n",
       "      <td>259</td>\n",
       "      <td>117</td>\n",
       "      <td>405</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>126</td>\n",
       "      <td>246</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               T1    T2    T3    T4     T5    T6     T7    T8    T9  T10  ...  \\\n",
       "date                                                                      ...   \n",
       "2020-02-23    673   486   196   402    699   218    466   206   208   40  ...   \n",
       "2020-02-24   7752  4876  3246  5651   9406  2829   6654  3283  3420  518  ...   \n",
       "2020-02-25   9122  6238  3479  5210  11693  3362   7785  3371  3462  585  ...   \n",
       "2020-02-26  10608  5316  3950  4863  13843  4025   9274  3422  3625  784  ...   \n",
       "2020-02-27  11899  6469  4443  4547  14894  5059  10891  3741  3708  790  ...   \n",
       "2020-02-28  10102  6501  4644  4318  12666  4694  10539  3584  3628  749  ...   \n",
       "2020-02-29   7104  2907  3324  4431   8268  3120   7229  2917  3645  416  ...   \n",
       "\n",
       "            T12  T13  T14  T15  T16  T17  T18  T19  T20  T21  \n",
       "date                                                          \n",
       "2020-02-23   10    9   33   17   34    6    3   19   23   16  \n",
       "2020-02-24  139  111  328  157  488   41   60  128  317  160  \n",
       "2020-02-25  137  104  293  148  561   45   60  131  317  135  \n",
       "2020-02-26  189  164  299  148  631   75   48  153  318  122  \n",
       "2020-02-27  218  161  271  137  677   77   55  176  324  137  \n",
       "2020-02-28  250  144  263  145  572   62   58  138  306  140  \n",
       "2020-02-29  181  104  259  117  405   55   47  126  246  114  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "outname = 'c_original.csv'\n",
    "outdir = '../results/jp'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "savename = os.path.join(outdir, outname)    \n",
    "\n",
    "dft.to_csv(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "outname = 'c_original.csv'\n",
    "outdir = '../results/jp/day'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "fullname = os.path.join(outdir, outname)    \n",
    "\n",
    "dft.to_csv(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
